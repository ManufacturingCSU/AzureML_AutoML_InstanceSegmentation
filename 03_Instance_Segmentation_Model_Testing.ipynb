{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9f630c6-d5b8-4e8d-97de-a70b7f63d391",
   "metadata": {},
   "source": [
    "# 03. AutoML Instance Segmentation Model Testing\n",
    "This notebook contains sample code to retrieve an instance segmentation model (trained using AutoML for Images) from the AML workspace, deploy that model to an Azure Kubernetes Service cluster (this resource is provisioned if it does not currently exist), then test the real-time endpoint by submitting an HTTP request with image data. Once a response is received, detected instances are annotated and displayed. \n",
    "\n",
    "<b><i>Note:</i></b> Only execute cells in this notebook after having run all cells in `01_Setup_AML_Env.ipynb` and `02_Create_AML_Model_Training_Pipeline.ipynb` and once your model training run has completed and successfully added a new model to your registry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbd61ef-8841-44bb-90e8-2bd5640497ab",
   "metadata": {},
   "source": [
    "### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10402e9-d86c-4e2b-b146-b3ec8153955c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment, Datastore, Environment, Dataset, Model, Run\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute, DataFactoryCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE, DEFAULT_GPU_IMAGE\n",
    "from azureml.pipeline.core import Pipeline, PipelineParameter, PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.pipeline.core import PipelineParameter, PipelineData\n",
    "from azureml.data.output_dataset_config import OutputTabularDatasetConfig, OutputDatasetConfig, OutputFileDatasetConfig\n",
    "from azureml.data.datapath import DataPath\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.data.sql_data_reference import SqlDataReference\n",
    "from azureml.pipeline.steps import DataTransferStep\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba6fdc0-a824-4112-a898-70d490a4a803",
   "metadata": {},
   "source": [
    "### Connect to AML workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296091ff-99c5-4bb7-844f-ff926e63ba3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7188d1-4eab-49e0-8c9f-089c1d82afb3",
   "metadata": {},
   "source": [
    "### Provision an Azure Kubernetes Service inferencing cluster\n",
    "Models that need to be deployed to real-time endpoints (to handle ad hoc, always-on image scoring) can be deployed to a variety of compute targets - [see this document for more details on different types of AML inference targets](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-and-where?tabs=azcli#choose-a-compute-target). For our demo here, we are provisioning an Azure Kubernetes Service cluster backed by a memory optimized VM type. This inferencing cluster can support large models and high volumes of inferencing traffic. Once the inferencing cluster is provisioned we can deploy our trained instance segmentation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba872f07-8de3-4bfe-bdba-a41e557bd658",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AksCompute\n",
    "from azureml.exceptions import ComputeTargetException\n",
    "\n",
    "# Choose a name for your cluster\n",
    "aks_name = \"cluster-aks\"\n",
    "\n",
    "# Check to see if the cluster already exists\n",
    "try:\n",
    "    aks_target = ComputeTarget(workspace=ws, name=aks_name)\n",
    "    print(\"Found existing compute target. So let's use it\")\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    # Provision AKS cluster with GPU machine\n",
    "    prov_config = AksCompute.provisioning_configuration(vm_size=\"Standard_DS13-4_v2\", \n",
    "                                                        location=\"eastus2\")\n",
    "    # Create the cluster\n",
    "    aks_target = ComputeTarget.create(workspace=ws, \n",
    "                                      name=aks_name, \n",
    "                                      provisioning_configuration=prov_config)\n",
    "    aks_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d78542-516e-465f-80a7-43f4d1b191d4",
   "metadata": {},
   "source": [
    "### Download and deploy model to local webservice\n",
    "Trained models registered in your AML workspace can be packaged into a docker container that exposes your model at an API endpoint through a Flask app. This container can be deployed to an authenticated online webservice or run locally. Here we are running this model to our AKS cluster which can be consumed via HTTP requests. See the documents below for tips on troubleshooting deployments by first testing your deployments locally. <b>Note: The step below may take some time to execute (5-15 min).</b>\n",
    "\n",
    "[Test and Troubleshoot a Local Model Deployment](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-deployment-local)\n",
    "\n",
    "[Deploy Machine Learning Models to Azure](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-and-where?tabs=azcli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab2c33a-7f94-42a2-aa7f-bb4a4eaccf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AksWebservice, LocalWebservice\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.environment import Environment\n",
    "\n",
    "model_name = 'Street_Segmentation_Model'\n",
    "deployment_name = 'street-segmentation-model'\n",
    "\n",
    "model_list = Model.list(ws, model_name)\n",
    "best_child_run_id = model_list[0].run_id\n",
    "best_child_run = Run.get(ws, best_child_run_id)\n",
    "model_list[0].download(exist_ok=True)\n",
    "model = model_list[0]\n",
    "environment = Environment.get(ws, 'AutoMLImages_ScoringEnv')\n",
    "inference_config = InferenceConfig(entry_script='score.py', environment=environment, source_directory='./automl_outputs') # model_path = './automl_outputs/outputs/model.pt'\n",
    "\n",
    "\n",
    "aks_config = AksWebservice.deploy_configuration(autoscale_enabled=True,                                                    \n",
    "                                                cpu_cores=1,\n",
    "                                                memory_gb=50,\n",
    "                                                enable_app_insights=True)\n",
    "\n",
    "aks_service = Model.deploy(ws,\n",
    "                           models=[model],\n",
    "                           inference_config=inference_config,\n",
    "                           deployment_config=aks_config,\n",
    "                           deployment_target=aks_target,\n",
    "                           name=deployment_name,\n",
    "                           overwrite=True)\n",
    "\n",
    "aks_service.wait_for_deployment(show_output=True)\n",
    "print()\n",
    "print(\"Done. Model is deployed.\")\n",
    "print(\"\\nAKS service status=\", aks_service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c640923-4612-4382-8917-4e89dfcb05c7",
   "metadata": {},
   "source": [
    "### Display Test Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1e08b5-56ba-43a2-ad63-ebccdfae07ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image \n",
    "img = Image(filename='./sample_images/SSDB00038.JPG')\n",
    "img.width = 750\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948c3e5f-af6d-4c89-a54f-6aadf8baaa02",
   "metadata": {},
   "source": [
    "### Evaluate and score sample image\n",
    "Submit an image from the test dataset to the AKS endpoint. The response from the endpoint should contain information about segmented instaces within the image and the code snippet below will annotate your sample image accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b257b8c-d7c0-41ec-a4ae-68d0e9c412bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.lines import Line2D\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import cv2\n",
    "\n",
    "_image = './sample_images/SSDB00038.JPG'\n",
    "data = open(sample_image, 'rb').read()\n",
    "# Set the content type\n",
    "headers = {'Content-Type': 'application/octet-stream', 'Authorization': f'Bearer {aks_service.get_keys()[0]}'}\n",
    "scoring_uri = aks_service.scoring_uri\n",
    "\n",
    "# Make the request and display the response\n",
    "resp = requests.post(scoring_uri, data, headers=headers)\n",
    "\n",
    "IMAGE_SIZE = (30,20)\n",
    "plt.figure(figsize=IMAGE_SIZE)\n",
    "img_np=mpimg.imread(sample_image)\n",
    "img = Image.fromarray(img_np.astype('uint8'),'RGB')\n",
    "x, y = img.size\n",
    "\n",
    "fig,ax = plt.subplots(1, figsize=IMAGE_SIZE)#, figsize=(20,20)\n",
    "# Display the image\n",
    "ax.imshow(img_np)\n",
    "\n",
    "covered_area  = 0.0\n",
    "total_area  = x * y\n",
    "\n",
    "covered_area_dict = {}\n",
    "label_count_dict = {}\n",
    "ax.set_axis_off()\n",
    "\n",
    "# draw box and label for each detection \n",
    "detections = json.loads(resp.text)\n",
    "for detect in detections['boxes']:\n",
    "    label = detect['label']\n",
    "    box = detect['box']\n",
    "    polygon = detect['polygon']\n",
    "    conf_score = detect['score']\n",
    "    if label not in covered_area_dict.keys():\n",
    "        covered_area_dict[label] = 0.0\n",
    "        label_count_dict[label] = 0\n",
    "    if conf_score > 0.6:\n",
    "        ymin, xmin, ymax, xmax =  box['topY'],box['topX'], box['bottomY'],box['bottomX']\n",
    "        topleft_x, topleft_y = x * xmin, y * ymin\n",
    "        width, height = x * (xmax - xmin), y * (ymax - ymin)\n",
    "        color = 'dodgerblue'\n",
    "        if label == 'car':\n",
    "            color = 'red'\n",
    "        polygon_np = np.array(polygon[0])\n",
    "        polygon_np = polygon_np.reshape(-1, 2)\n",
    "        polygon_np[:, 0] *= x\n",
    "        polygon_np[:, 1] *= y\n",
    "        poly = patches.Polygon(polygon_np, True, facecolor=color, alpha=0.25)\n",
    "        ax.add_patch(poly)\n",
    "        poly_line = Line2D(polygon_np[:, 0], polygon_np[:, 1], linewidth=2,\n",
    "                           marker='o', markersize=0, markerfacecolor=color, color=color)\n",
    "        ax.add_line(poly_line)\n",
    "\n",
    "        covered_area_dict[label] += cv2.contourArea(np.array(poly.xy).reshape((-1,1,2)).astype(np.int32))\n",
    "        label_count_dict[label]+=1\n",
    "\n",
    "plt.show()\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3495b604-f941-4feb-b68a-7421f734f5bd",
   "metadata": {},
   "source": [
    "### Demo Complete! \n",
    "This marks the end of the AutoML for Images - Instance Segmentation demo! To continue building upon this sample try labeling your own image dataset using [Azure ML's data labeling tools](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-label-data). Labeled datasets can be exported and passed as inputs to the `PipelineEndpoint` you created earlier in this sample to train new instance segmentation models built around your specific data. These models can then be deployed and consumed as shown above!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
